{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08de4a2b-c2c3-4f6a-a917-f9e26c31f16c",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3e9653-1834-4727-a4c7-ee69e6ae7daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T04:46:09.731203Z",
     "iopub.status.busy": "2023-09-09T04:46:09.730854Z",
     "iopub.status.idle": "2023-09-09T04:46:10.072126Z",
     "shell.execute_reply": "2023-09-09T04:46:10.069916Z",
     "shell.execute_reply.started": "2023-09-09T04:46:09.731182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/apps/rhel8/jupyter/2023-04/lib/python3.10/site-packages/nvidia/cudnn\n",
      "/usr/local/cuda/lib64:/usr/local/cuda/lib64:/app/apps/rhel8/jupyter/2023-04/lib/python3.10/site-packages/nvidia/cudnn/lib:/app/apps/rhel8/jupyter/2023-04/lib/python3.10/site-packages/tensorrt_libs:/app/apps/rhel8/python-anaconda3/2023-04/lib::\n",
      "/app/apps/rhel8/jupyter/2023-04/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/jupyterhub/bin:/common/bin:/usr/local/cuda/bin:/usr/localsys/bin:/usr/share/Modules/bin:/bin\n"
     ]
    }
   ],
   "source": [
    "## note we need to make sure these environment variables are set properly for tensorflow to properly make use of the GPU\n",
    "# should be: /app/apps/rhel8/jupyter/2023-04/lib/python3.10/site-packages/nvidia/cudnn\n",
    "!echo $CUDNN_PATH\n",
    "# should be: /usr/local/cuda/lib64:/usr/local/cuda/lib64:/app/apps/rhel8/jupyter/2023-04/lib/python3.10/site-packages/nvidia/cudnn/lib:/app/apps/rhel8/jupyter/2023-04/lib/python3.10/site-packages/tensorrt_libs:/app/apps/rhel8/python-anaconda3/2023-04/lib::\n",
    "!echo $LD_LIBRARY_PATH\n",
    "# must include: /app/apps/rhel8/jupyter/2023-04/bin:/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/jupyterhub/bin:/common/bin:/usr/local/cuda/bin:/usr/localsys/bin:/usr/share/Modules/bin\n",
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db821e3-a86f-4906-99da-97f8fcad7de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T04:46:10.074609Z",
     "iopub.status.busy": "2023-09-09T04:46:10.074165Z",
     "iopub.status.idle": "2023-09-09T04:46:14.881945Z",
     "shell.execute_reply": "2023-09-09T04:46:14.881036Z",
     "shell.execute_reply.started": "2023-09-09T04:46:10.074586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 00:46:10.449373: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-09 00:46:10.506295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba470b5e-0d5d-4a9c-b537-8811bc3cb2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T04:46:14.883137Z",
     "iopub.status.busy": "2023-09-09T04:46:14.882724Z",
     "iopub.status.idle": "2023-09-09T04:46:14.886147Z",
     "shell.execute_reply": "2023-09-09T04:46:14.885678Z",
     "shell.execute_reply.started": "2023-09-09T04:46:14.883113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3206fbc-304d-4c9e-b18e-b3731881a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T04:46:14.887164Z",
     "iopub.status.busy": "2023-09-09T04:46:14.886792Z",
     "iopub.status.idle": "2023-09-09T04:46:15.000773Z",
     "shell.execute_reply": "2023-09-09T04:46:15.000270Z",
     "shell.execute_reply.started": "2023-09-09T04:46:14.887145Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "import time\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ef9f86-69a0-422e-8af9-d5cf9988d680",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T04:46:15.001704Z",
     "iopub.status.busy": "2023-09-09T04:46:15.001448Z",
     "iopub.status.idle": "2023-09-09T04:46:16.307738Z",
     "shell.execute_reply": "2023-09-09T04:46:16.307225Z",
     "shell.execute_reply.started": "2023-09-09T04:46:15.001685Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 00:46:16.301499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14551 MB memory:  -> device: 0, name: Tesla P6, pci bus id: 0000:18:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/device:CPU:0', '/device:GPU:0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU' or x.device_type == 'CPU']\n",
    "get_available_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbef3c-bb07-4f69-8d3e-dea9d8384951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-09T04:46:16.308770Z",
     "iopub.status.busy": "2023-09-09T04:46:16.308455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 00:46:17.505901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14551 MB memory:  -> device: 0, name: Tesla P6, pci bus id: 0000:18:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 00:46:19.958591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-09-09 00:46:20.209418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9e1adc5d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-09 00:46:20.209452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P6, Compute Capability 6.1\n",
      "2023-09-09 00:46:20.215517: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-09 00:46:20.368741: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 9s 4ms/step - loss: 1.5949 - accuracy: 0.4099 - val_loss: 1.2792 - val_accuracy: 0.5387\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1956 - accuracy: 0.5746 - val_loss: 1.1261 - val_accuracy: 0.5985\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0321 - accuracy: 0.6364 - val_loss: 1.0185 - val_accuracy: 0.6446\n",
      "Epoch 4/10\n",
      " 601/1563 [==========>...................] - ETA: 2s - loss: 0.9378 - accuracy: 0.6669"
     ]
    }
   ],
   "source": [
    "# Download and prepare the CIFAR10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Create the convolutional base\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add Dense layers on top\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# Fit the model on GPU\n",
    "start_time = time.time()\n",
    "history = model.fit(train_images, train_labels, epochs=10,\n",
    "                    validation_data=(test_images, test_labels))\n",
    "end_time = time.time()\n",
    "print(\"Time to fit model on GPU: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_images, test_labels)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f4b7d-d13c-4171-bdb4-37b0e481bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that I wrote for the PDFF imputation project using a baseline_mlp model\n",
    "!cd /home/craut/wkspce/craut_lfs/MRI_PDFF_imputation/fit_models/ && time python evaluate_model.py -dd ../cut_data_again/real_data/ -od output2 -m baseline_mlp -tr -te -i simple"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
